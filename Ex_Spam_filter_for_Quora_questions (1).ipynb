{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd2K-1li9MH8"
      },
      "source": [
        "Project 3: Spam filter for Quora questions\n",
        "Download data from here : https://www.dropbox.com/sh/kpf9z73woodfssv/AAAw1_JIzpuVvwteJCma0xMla?dl=0\n",
        "\n",
        "Goal : Build a model for identifying if a question on Quora is spam\n",
        "\n",
        "Suggested Guidelines :\n",
        "\n",
        "1. To bring down dimensions of your model you can use glove embedding shared with you ( in the data )\n",
        "\n",
        "2. Here is how you can use pertained embeddings : https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
        "\n",
        "3. You'll have to Create and maintain your own train/validation splits for the full data shared with you\n",
        "\n",
        "4. Your solution needs to be uploaded to GitHub repo of your team"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1If51Jr8RN1"
      },
      "outputs": [],
      "source": [
        "# tags dataset column- qid, question_text, target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ7BZ3fUmhfK",
        "outputId": "52379eb2-1bce-44e8-95a7-b15303230ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv5ne1tZIskE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73MPHuuvIyop"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Datasets/DL P3 Qura spam/train (1) (1).csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VreBhGjNW6G",
        "outputId": "2d04bba8-cc05-4330-9c3b-c5d0c2e260be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1048575 entries, 0 to 1048574\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count    Dtype \n",
            "---  ------         --------------    ----- \n",
            " 0   qid            1048575 non-null  object\n",
            " 1   question_text  1048575 non-null  object\n",
            " 2   target         1048575 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 24.0+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "text_train, text_val, labels_train, labels_val = train_test_split(df['question_text'], df['target'], test_size=0.2)\n"
      ],
      "metadata": {
        "id": "VLAV4rcvU5jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Create tokenizer\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(text_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "gBhOvEpSU5lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, Dropout,Flatten\n",
        "\n"
      ],
      "metadata": {
        "id": "MAHxYNflU5pF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(text_train)\n",
        "val_sequences = tokenizer.texts_to_sequences(text_val)\n"
      ],
      "metadata": {
        "id": "B5Bi_9TXU5rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences\n",
        "max_length = 200\n",
        "train_sequences_padded = pad_sequences(train_sequences, maxlen=max_length)\n",
        "val_sequences_padded = pad_sequences(val_sequences, maxlen=max_length)\n",
        "\n",
        "\n",
        "\n",
        "# One-hot encode labels\n",
        "labels_train_onehot = to_categorical(labels_train)\n",
        "labels_val_onehot = to_categorical(labels_val)\n",
        "\n"
      ],
      "metadata": {
        "id": "L11TRAEgU5wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "vocab_size = 10000\n",
        "embedding_dim = 100\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())  # Added Flatten layer\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A-5r9rCYU51z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "J7YoIxoAU55O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model.fit(train_sequences_padded, labels_train_onehot, validation_data=(val_sequences_padded, labels_val_onehot), epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oou2NBgyU58B",
        "outputId": "48655088-fc8b-4ba2-8553-de9dc3fbd656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m26215/26215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1420s\u001b[0m 54ms/step - accuracy: 0.9473 - loss: 0.1454 - val_accuracy: 0.9526 - val_loss: 0.1212\n",
            "Epoch 2/5\n",
            "\u001b[1m26215/26215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1438s\u001b[0m 53ms/step - accuracy: 0.9543 - loss: 0.1194 - val_accuracy: 0.9526 - val_loss: 0.1265\n",
            "Epoch 3/5\n",
            "\u001b[1m26215/26215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1398s\u001b[0m 53ms/step - accuracy: 0.9569 - loss: 0.1115 - val_accuracy: 0.9524 - val_loss: 0.1257\n",
            "Epoch 4/5\n",
            "\u001b[1m26215/26215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1447s\u001b[0m 55ms/step - accuracy: 0.9609 - loss: 0.1013 - val_accuracy: 0.9516 - val_loss: 0.1411\n",
            "Epoch 5/5\n",
            "\u001b[1m26215/26215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1493s\u001b[0m 56ms/step - accuracy: 0.9639 - loss: 0.0952 - val_accuracy: 0.9510 - val_loss: 0.1425\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c30cad6d6f0>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "loss, accuracy = model.evaluate(val_sequences_padded, labels_val_onehot)\n",
        "print(f'Validation accuracy: {accuracy:.3f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8f1kkkXYDAX",
        "outputId": "0a265fb2-3d7b-4a45-f7d5-6063f63883cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6554/6554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 7ms/step - accuracy: 0.9513 - loss: 0.1416\n",
            "Validation accuracy: 0.951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(val_sequences_padded)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPWYiWjsYDBw",
        "outputId": "bb9c7d47-648a-410f-df3e-447c299415d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6554/6554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert one-hot encoded val_labels to class labels\n",
        "labels_val_onehot = np.argmax(labels_val_onehot, axis=1)\n"
      ],
      "metadata": {
        "id": "wbwBhR_f-yBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate predictions\n",
        "print('Classification Report:')\n",
        "print(classification_report(labels_val_onehot, predicted_labels))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(labels_val_onehot, predicted_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNSfCu1ZYDGb",
        "outputId": "c9435590-9b21-48bc-abdd-4ae30ac80e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97    196709\n",
            "           1       0.66      0.44      0.53     13006\n",
            "\n",
            "    accuracy                           0.95    209715\n",
            "   macro avg       0.81      0.71      0.75    209715\n",
            "weighted avg       0.94      0.95      0.95    209715\n",
            "\n",
            "Confusion Matrix:\n",
            "[[193745   2964]\n",
            " [  7309   5697]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is completed"
      ],
      "metadata": {
        "id": "o2P35O58_MZs"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}